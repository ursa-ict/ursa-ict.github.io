<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>Artificial Intelligence Security - Tag - XPU-driven Research on System and Architecture @ ICT, CAS</title><link>https://ursa-ict.github.io/tags/artificial-intelligence-security/</link><description>Artificial Intelligence Security - Tag - XPU-driven Research on System and Architecture @ ICT, CAS</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Thu, 12 May 2022 09:40:28 +0800</lastBuildDate><atom:link href="https://ursa-ict.github.io/tags/artificial-intelligence-security/" rel="self" type="application/rss+xml"/><item><title>人工智能安全</title><link>https://ursa-ict.github.io/posts/artificial-intelligence-security/</link><pubDate>Thu, 12 May 2022 09:40:28 +0800</pubDate><author>Author</author><guid>https://ursa-ict.github.io/posts/artificial-intelligence-security/</guid><description>Introduction The past several years have witnessed the rapid development of Deep Learning technology. Various DL models today are widely adopted in many scenarios, e.g., image classification, speech recognition, language processing, robotics control. These applications significantly enhance the quality of life. However, new security threats are introduced to DNN models including backdoor attacks, adversarial attacks, model extraction attacks, privacy inference attacks, etc. It is critical to protect these DNN models against existing or potential integrity and privacy attacks, especially in safety-critical fields such as autonomous driving and smart medical care.</description></item></channel></rss>